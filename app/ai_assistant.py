import os
import random
from pathlib import Path
from datetime import datetime
from transformers import AutoTokenizer, AutoModelForCausalLM
from huggingface_hub import InferenceClient

BASE_DIR = Path(__file__).parent

# üîπ –ü—É—Ç–∏ –∫ –ª–æ–∫–∞–ª—å–Ω—ã–º –º–æ–¥–µ–ª—è–º
RU_LOCAL = (BASE_DIR / "models" / "rugpt3small").resolve()
EN_LOCAL = (BASE_DIR / "models" / "distilgpt2").resolve()

# üîπ –ú–æ–¥–µ–ª–∏ Hugging Face
HF_MODELS = {
    "ru": "ai-forever/FRED-T5-1.7B",
    "en": "mistralai/Mistral-7B-Instruct-v0.2",
}

HF_TOKEN = os.getenv("HF_TOKEN", "HF_TOKEN_HERE")

# üîπ –°–ª–æ–≤–∞—Ä—å –¥–ª—è –ª–µ–Ω–∏–≤–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π
_models = {}


def _load_local_model(lang):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏"""
    path = RU_LOCAL if lang == "ru" else EN_LOCAL
    if not os.path.isdir(path):
        return None, None
    try:
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–∞–µ–º –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –∏–∑ {path}")
        tokenizer = AutoTokenizer.from_pretrained(path, local_files_only=True)
        model = AutoModelForCausalLM.from_pretrained(path, local_files_only=True)
        _models[lang] = (tokenizer, model)
        return tokenizer, model
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏: {e}")
        return None, None


def _generate_local(prompt, lang="ru"):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å (fallback)"""
    tokenizer, model = _models.get(lang, (None, None))
    if tokenizer is None or model is None:
        tokenizer, model = _load_local_model(lang)
        if tokenizer is None:
            return None

    inputs = tokenizer(prompt, return_tensors="pt")
    output = model.generate(
        **inputs,
        max_length=200,
        temperature=0.8,
        top_p=0.9,
        do_sample=True,
        pad_token_id=tokenizer.eos_token_id,
    )
    text = tokenizer.decode(output[0], skip_special_tokens=True)
    return text.replace(prompt, "").strip()


def _generate_hf(prompt, lang="ru"):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Hugging Face API"""
    model_name = HF_MODELS["ru"] if lang == "ru" else HF_MODELS["en"]
    print(f"üåê –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ Hugging Face API ({model_name})...")

    client = InferenceClient(model=model_name, token=HF_TOKEN)

    try:
        # üß† –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä Mistral) —Ä–∞–±–æ—Ç–∞—é—Ç —Ç–æ–ª—å–∫–æ –≤ —Ä–µ–∂–∏–º–µ "conversational"
        if "mistral" in model_name.lower():
            messages = [
                {
                    "role": "system",
                    "content": "You are a helpful and concise time management assistant.",
                },
                {"role": "user", "content": prompt},
            ]
            response = client.chat_completion(messages, max_tokens=250, temperature=0.7)
            return response.choices[0].message["content"].strip()
        else:
            # üîπ –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º text-generation (–¥–ª—è FRED-T5 –∏ –¥—Ä—É–≥–∏—Ö)
            response = client.text_generation(
                prompt,
                max_new_tokens=200,
                temperature=0.7,
                top_p=0.9,
                repetition_penalty=1.1,
            )
            return response.strip()
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Hugging Face API: {e}")
        return None


def get_task_advice(task, lang="ru"):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–æ–≤–µ—Ç–∞ –ø–æ —Ç–∞–π–º-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç—É"""
    title = getattr(task, "title", "")
    desc = getattr(task, "description", "")
    allocated = getattr(task, "allocated_time", 0)
    deadline = getattr(task, "deadline", None)
    pomo_work = getattr(task, "pomodoro_work", 25)
    pomo_break = getattr(task, "pomodoro_break", 5)

    now = datetime.now()
    days_left = None
    if deadline:
        try:
            deadline_date = deadline.date() if hasattr(deadline, "date") else deadline
            days_left = (deadline_date - now.date()).days
        except Exception:
            days_left = None

    if lang == "ru":
        prompt = (
            "–¢—ã ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ —Ç–∞–π–º-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç—É. "
            "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∑–∞–¥–∞—á—É –∏ –¥–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π, –∫—Ä–∞—Ç–∫–∏–π —Å–æ–≤–µ—Ç –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏.\n\n"
            f"–ó–∞–¥–∞—á–∞: {title}\n"
            f"–û–ø–∏—Å–∞–Ω–∏–µ: {desc}\n"
            f"–í—ã–¥–µ–ª–µ–Ω–æ –≤—Ä–µ–º–µ–Ω–∏: {allocated} –º–∏–Ω.\n"
            f"–î–µ–¥–ª–∞–π–Ω: {days_left if days_left is not None else '–Ω–µ –∑–∞–¥–∞–Ω'} –¥–Ω.\n"
            f"Pomodoro: {pomo_work}/{pomo_break} –º–∏–Ω.\n"
            "–°–æ–≤–µ—Ç:"
        )
    else:
        prompt = (
            "You are an expert time management assistant. "
            "Analyze the task and give a concise, practical productivity tip.\n\n"
            f"Task: {title}\n"
            f"Description: {desc}\n"
            f"Allocated time: {allocated} min.\n"
            f"Deadline: {days_left if days_left is not None else 'not set'} days.\n"
            f"Pomodoro: {pomo_work}/{pomo_break} min.\n"
            "Tip:"
        )

    # 1Ô∏è‚É£ –ü—ã—Ç–∞–µ–º—Å—è —á–µ—Ä–µ–∑ API
    try:
        text = _generate_hf(prompt, lang)
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ API Hugging Face: {e}")
        text = None

    # 2Ô∏è‚É£ –ï—Å–ª–∏ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ ‚Äî fallback –Ω–∞ –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
    if not text:
        text = _generate_local(prompt, lang)

    # 3Ô∏è‚É£ –ï—Å–ª–∏ —Å–æ–≤—Å–µ–º –Ω–∏—á–µ–≥–æ ‚Äî —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–æ–≤–µ—Ç
    if not text or len(text) < 10:
        backup_ru = [
            "–†–∞–∑–±–µ–π –∑–∞–¥–∞—á—É –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —à–∞–≥–∏ –∏ –Ω–∞—á–Ω–∏ —Å —Å–∞–º–æ–≥–æ –ø—Ä–æ—Å—Ç–æ–≥–æ.",
            "–í—ã–¥–µ–ª–∏ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –∏ —Ä–∞–±–æ—Ç–∞–π –≤ –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ñ–æ–∫—É—Å-—Å–µ—Å—Å–∏—è—Ö.",
            "–ü–æ—Å—Ç–∞–≤—å —Ç–∞–π–º–µ—Ä –∏ –∏–∑–±–µ–≥–∞–π –æ—Ç–≤–ª–µ–∫–∞—é—â–∏—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤.",
        ]
        backup_en = [
            "Break the task into specific steps and start with the simplest one.",
            "Set clear priorities and work in focused short sessions.",
            "Use a timer and minimize distractions.",
        ]
        text = random.choice(backup_ru if lang == "ru" else backup_en)

    return text.strip()
